<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta name="description" content="A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers. EDIT stands for Evaluation of Developer Instructed Tasks.">
  <meta name="keywords" content="code editing, LLM benchmark, code generation, AI coding assistants, real-world evaluation, machine learning">
  <meta name="author" content="Wayne Chi, Valerie Chen, Ryan Shar, Aditya Mittal, Jenny Liang, Wei-Lin Chiang, Anastasios Nikolas Angelopoulos, Ion Stoica, Graham Neubig, Ameet Talwalkar, Chris Donahue">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Carnegie Mellon University">
  <meta property="og:title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta property="og:description" content="A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers. EDIT stands for Evaluation of Developer Instructed Tasks.">
  <meta property="og:url" content="https://editbench.github.io">
  <meta property="og:image" content="https://editbench.github.io/editbench-icon.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="EDIT-bench - Real-World Code Editing Benchmark">
  <meta property="article:published_time" content="2026-01-01T00:00:00.000Z">
  <meta property="article:author" content="Wayne Chi">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="code editing">
  <meta property="article:tag" content="LLM benchmark">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@CarnegieMellon">
  <meta name="twitter:creator" content="@CarnegieMellon">
  <meta name="twitter:title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta name="twitter:description" content="A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers. EDIT stands for Evaluation of Developer Instructed Tasks.">
  <meta name="twitter:image" content="https://editbench.github.io/editbench-icon.png">
  <meta name="twitter:image:alt" content="EDIT-bench - Real-World Code Editing Benchmark">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta name="citation_author" content="Chi, Wayne">
  <meta name="citation_author" content="Chen, Valerie">
  <meta name="citation_author" content="Shar, Ryan">
  <meta name="citation_author" content="Mittal, Aditya">
  <meta name="citation_author" content="Liang, Jenny">
  <meta name="citation_author" content="Chiang, Wei-Lin">
  <meta name="citation_author" content="Angelopoulos, Anastasios Nikolas">
  <meta name="citation_author" content="Stoica, Ion">
  <meta name="citation_author" content="Neubig, Graham">
  <meta name="citation_author" content="Talwalkar, Ameet">
  <meta name="citation_author" content="Donahue, Chris">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_pdf_url" content="https://editbench.github.io/edit-bench.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>EDIT-bench | Real-World Code Editing Benchmark</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/png" href="editbench-icon.png">
  <link rel="apple-touch-icon" href="editbench-icon.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits",
    "description": "A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers.",
    "author": [
      {"@type": "Person", "name": "Wayne Chi", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Valerie Chen", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Ryan Shar", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Aditya Mittal", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Jenny Liang", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Wei-Lin Chiang", "affiliation": {"@type": "Organization", "name": "UC Berkeley"}},
      {"@type": "Person", "name": "Anastasios Nikolas Angelopoulos", "affiliation": {"@type": "Organization", "name": "UC Berkeley"}},
      {"@type": "Person", "name": "Ion Stoica", "affiliation": {"@type": "Organization", "name": "UC Berkeley"}},
      {"@type": "Person", "name": "Graham Neubig", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Ameet Talwalkar", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Chris Donahue", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}}
    ],
    "datePublished": "2026-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "Carnegie Mellon University"
    },
    "url": "https://editbench.github.io",
    "image": "https://editbench.github.io/editbench-icon.png",
    "keywords": ["code editing", "LLM benchmark", "code generation", "AI coding assistants", "real-world evaluation", "machine learning"],
    "abstract": "Instructed code editing is becoming a widely used interaction mode in AI coding assistants. We introduce EDIT-bench, a benchmark for evaluating LLM code editing capabilities grounded in real-world usage with 540 problems collected from nearly 500 developers.",
    "isAccessibleForFree": true,
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://editbench.github.io"
    },
    "about": [
      {"@type": "Thing", "name": "Code Editing"},
      {"@type": "Thing", "name": "LLM Evaluation"}
    ]
  }
  </script>

  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Carnegie Mellon University",
    "url": "https://www.cmu.edu",
    "logo": "https://editbench.github.io/editbench-icon.png",
    "sameAs": [
      "https://twitter.com/CarnegieMellon",
      "https://github.com/editbench"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero" style="background-color: #faf1dc;">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div style="display: flex; align-items: center; justify-content: center; gap: 1rem; margin-bottom: 1rem;">
              <img src="editbench-icon.png" alt="EDIT-bench Logo" style="height: 150px; width: 150px;">
              <h1 class="title is-1 publication-title" style="margin-bottom: 0;">EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits</h1>
            </div>
            <div class="is-size-6 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Wayne Chi</a><sup>*1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Valerie Chen</a><sup>*1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ryan Shar</a><sup>*1</sup></span>
            </div>
            <div class="is-size-6 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Aditya Mittal</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Jenny Liang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Wei-Lin Chiang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Anastasios Nikolas Angelopoulos</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ion Stoica</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Graham Neubig</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ameet Talwalkar</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Chris Donahue</a><sup>1</sup></span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="eql-cntrb"><small><sup>*</sup>Equal Contribution</small></span>
            </div>

            <div class="is-size-6 publication-authors" style="margin-top: 0.5rem;">
              <span class="author-block"><sup>1</sup>Carnegie Mellon University</span>
              &nbsp;&nbsp;
              <span class="author-block"><sup>2</sup>UC Berkeley</span>
            </div>

                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2511.04486" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                <span class="link-block">
                  <a href="https://github.com/waynchi/editbench" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://huggingface.co/datasets/copilot-arena/editbench" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-database"></i>
                </span>
                <span>Dataset</span>
              </a>
            </span>

            </div>
          </div>
        </div>
      </div>
    </div>
</section>


<!-- TLDR -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">TL;DR</h2>
      <div class="content has-text-justified" style="font-size: 1.1rem;">
        <p>
          <strong>EDIT-bench</strong> (Evaluation of Developer Instructed Tasks) is the first benchmark for evaluating LLM code editing capabilities built on <strong>real-world edit contexts and instructions</strong> collected in-the-wild. We gathered data from nearly 500 developers using a VS Code extension, creating 540 problems across 5 natural languages and 2 programming languages. EDIT-bench tests models on diverse, context-dependent problems that require understanding user instructions, code context, highlighted code, and cursor position—reflecting how developers actually use AI coding assistants.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End TLDR -->



<!-- Leaderboard -->
<section class="hero is-small" id="results">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">EDIT-bench Leaderboard</h2>
      <p class="has-text-centered" style="margin-bottom: 2rem;">
        Pass rates for LLMs on EDIT-bench. <strong>Core:</strong> 108 problems (subset) | <strong>Complete:</strong> 540 problems (full set). Higher is better.
      </p>
      <div class="table-container" style="max-height: 600px; overflow-y: auto; border: 1px solid #e5e7eb; border-radius: 8px;">
        <table class="table is-hoverable is-fullwidth" style="margin: 0;">
          <thead style="position: sticky; top: 0; z-index: 10;">
            <tr style="background-color: #2563EB; color: white;">
              <th style="color: white;">Rank</th>
              <th style="color: white;">Model</th>
              <th style="color: white;">Core (%)</th>
              <th style="color: white;">Complete (%)</th>
              <th style="color: white;">Type</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>1</td><td>claude-sonnet-4</td><td>66.67</td><td><strong>64.81</strong></td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>2</td><td>claude-sonnet-4.5</td><td>60.19</td><td>59.81</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>3</td><td>claude-3.7-sonnet</td><td>62.04</td><td>59.26</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>4</td><td>claude-3.5-sonnet</td><td>63.89</td><td>59.07</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>5</td><td>kimi-k2-0905</td><td>58.33</td><td>56.48</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>6</td><td>glm-4.6</td><td>55.56</td><td>56.48</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>7</td><td>gpt-o3-mini</td><td>62.96</td><td>56.30</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>8</td><td>deepseek-chat-v3.1</td><td>59.26</td><td>54.26</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>9</td><td>gpt-5-mini</td><td>52.78</td><td>54.07</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>10</td><td>qwen3-coder</td><td>55.56</td><td>53.89</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>11</td><td>gpt-o4-mini (high)</td><td>59.26</td><td>53.70</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>12</td><td>gpt-4o</td><td>53.70</td><td>53.33</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>13</td><td>gpt-o3-mini (high)</td><td>53.70</td><td>52.78</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>14</td><td>gpt-5 (high)</td><td>56.48</td><td>52.78</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>15</td><td>gpt-o4-mini</td><td>57.41</td><td>52.78</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>16</td><td>grok-4-fast</td><td>52.78</td><td>52.04</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>17</td><td>gemini-2.5-flash</td><td>51.85</td><td>51.85</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>18</td><td>gemini-2.5-pro</td><td>54.63</td><td>51.30</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>19</td><td>grok-code-fast-1</td><td>53.70</td><td>50.93</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>20</td><td>qwen3-coder-flash</td><td>51.85</td><td>50.74</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>21</td><td>llama-3.3-70b-instruct</td><td>51.85</td><td>49.63</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>22</td><td>llama-4-maverick</td><td>50.93</td><td>49.44</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>23</td><td>gpt-5</td><td>51.85</td><td>49.26</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>24</td><td>llama-3.1-405b-instruct</td><td>48.15</td><td>48.70</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>25</td><td>gpt-oss-20b</td><td>50.00</td><td>48.15</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>26</td><td>gpt-4o-mini</td><td>50.00</td><td>47.78</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>27</td><td>mistral-small-3.2-24b-instruct</td><td>43.52</td><td>46.30</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>28</td><td>qwen3-14b</td><td>47.22</td><td>45.93</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>29</td><td>gpt-5-nano</td><td>47.22</td><td>45.74</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>30</td><td>qwen-2.5-72b-instruct</td><td>53.70</td><td>45.19</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>31</td><td>mistralai-codestral-2508</td><td>43.52</td><td>44.81</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>32</td><td>deepseek-r1-0528</td><td>41.67</td><td>44.44</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>33</td><td>llama-4-scout</td><td>45.37</td><td>43.33</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>34</td><td>qwen3-30b-a3b</td><td>43.52</td><td>43.15</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>35</td><td>gpt-oss-120b</td><td>44.44</td><td>41.30</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>36</td><td>devstral-medium</td><td>50.00</td><td>41.11</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>37</td><td>qwen-2.5-coder-32b-instruct</td><td>53.70</td><td>40.00</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>38</td><td>gemma-3-27b-it</td><td>29.63</td><td>37.04</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>39</td><td>devstral-small</td><td>48.15</td><td>36.67</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>40</td><td>llama-3.1-8b-instruct</td><td>37.96</td><td>34.07</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>41</td><td>kimi-dev-72b</td><td>33.33</td><td>31.67</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>42</td><td>gemma-3-12b-it</td><td>23.15</td><td>30.00</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>43</td><td>gemma-3n-e4b-it</td><td>31.48</td><td>29.26</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>44</td><td>glm-4.5</td><td>29.63</td><td>29.07</td><td><span class="tag is-success">Open</span></td></tr>
          </tbody>
        </table>
      </div>
      <p class="has-text-centered" style="margin-top: 1.5rem; font-size: 0.9rem; color: #666;">
        Full results: <a href="results-core.csv" style="color: #2563EB; font-weight: 600;">Core (108)</a> | <a href="results-complete.csv" style="color: #2563EB; font-weight: 600;">Complete (540)</a>
      </p>
    </div>
  </div>
</section>
<!-- End leaderboard -->







<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">Citation</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@misc{chi2025editbenchevaluatingllmabilities,
      title={EDIT-Bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits},
      author={Wayne Chi and Valerie Chen and Ryan Shar and Aditya Mittal and Jenny Liang and Wei-Lin Chiang and Anastasios Nikolas Angelopoulos and Ion Stoica and Graham Neubig and Ameet Talwalkar and Chris Donahue},
      year={2025},
      eprint={2511.04486},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2511.04486},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
