<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta name="description" content="A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers. EDIT stands for Evaluation of Developer Instructed Tasks.">
  <meta name="keywords" content="code editing, LLM benchmark, code generation, AI coding assistants, real-world evaluation, machine learning">
  <meta name="author" content="Wayne Chi, Valerie Chen, Ryan Shar, Aditya Mittal, Jenny Liang, Wei-Lin Chiang, Anastasios Nikolas Angelopoulos, Ion Stoica, Graham Neubig, Ameet Talwalkar, Chris Donahue">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>EDIT-bench | Real-World Code Editing Benchmark</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits</h1>
            <div class="is-size-6 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Wayne Chi</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Valerie Chen</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ryan Shar</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Aditya Mittal</a>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Jenny Liang</a>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Wei-Lin Chiang</a>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Anastasios Nikolas Angelopoulos</a>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ion Stoica</a>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Graham Neubig</a>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ameet Talwalkar</a>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Chris Donahue</a></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Under review as a conference paper at ICLR 2026</span>
              <span class="eql-cntrb"><small><br><sup>*</sup>Equal Contribution</small></span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="edit-bench.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <span class="link-block">
                    <a href="https://github.com/editbench/editbench" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="heb-results.csv" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-table"></i>
                  </span>
                  <span>Results</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- TLDR -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">TL;DR</h2>
      <div class="content has-text-justified" style="font-size: 1.1rem;">
        <p>
          <strong>EDIT-bench</strong> (Evaluation of Developer Instructed Tasks) is the first benchmark for evaluating LLM code editing capabilities built on <strong>real-world edit contexts and instructions</strong> collected in-the-wild. We gathered data from nearly 500 developers using a VS Code extension, creating 545 problems across 5 natural languages and 2 programming languages. EDIT-bench tests models on diverse, context-dependent problems that require understanding user instructions, code context, highlighted code, and cursor position—reflecting how developers actually use AI coding assistants.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End TLDR -->

<!-- Key Takeaways -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Key Takeaways</h2>
        <div class="content">
          <ul style="font-size: 1.05rem;">
            <li><strong>Real-world data:</strong> EDIT-bench is built from actual developer workflows, with user instructions and code contexts collected from 500 developers using our VS Code extension.</li>
            <li><strong>Challenging benchmark:</strong> Only 3 out of 40 models achieve over 60% pass@1, with claude-sonnet-4 leading at 66.67%.</li>
            <li><strong>Context matters:</strong> Model performance varies up to 11% depending on contextual information (highlighted code, cursor position), demonstrating the importance of realistic evaluation.</li>
            <li><strong>Diverse problems:</strong> 545 problems spanning 5 natural languages (English, Spanish, Russian, Chinese, Portuguese), 2 programming languages (Python, JavaScript), and 4 edit categories (feature addition, modification, bug fixing, optimization).</li>
            <li><strong>Model performance varies by task:</strong> Models excel at different problem categories—some are better at bug fixing (52.2% avg), while struggling with optimization (44.6% avg) and feature addition (39.6% avg).</li>
            <li><strong>Weak correlation with existing benchmarks:</strong> EDIT-bench shows only weak correlation with Aider Polyglot (r=0.24) and Chatbot Arena (r=0.11), suggesting it captures unique real-world editing challenges.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End key takeaways -->


<!-- Leaderboard -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">EDIT-bench Leaderboard</h2>
      <p class="has-text-centered" style="margin-bottom: 2rem;">
        Pass rates for 40 LLMs on EDIT-bench (545 problems). Higher is better.
      </p>
      <div class="table-container" style="max-height: 600px; overflow-y: auto; border: 1px solid #e5e7eb; border-radius: 8px;">
        <table class="table is-striped is-hoverable is-fullwidth" style="margin: 0;">
          <thead style="position: sticky; top: 0; z-index: 10;">
            <tr style="background-color: #2563EB; color: white;">
              <th style="color: white;">Rank</th>
              <th style="color: white;">Model</th>
              <th style="color: white;">Pass Rate (%)</th>
              <th style="color: white;">Type</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>1</td><td>claude-sonnet-4</td><td><strong>66.67</strong></td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>2</td><td>gpt-o3-mini</td><td>63.89</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>3</td><td>claude-3.5-sonnet</td><td>62.04</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>4</td><td>claude-3-7-sonnet</td><td>59.48</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>5</td><td>deepseek-chat-v3.1</td><td>58.88</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>6</td><td>gpt-o4-mini-high</td><td>58.33</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>7</td><td>gpt-o4-mini</td><td>57.55</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>8</td><td>kimi-k2-0905</td><td>57.41</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>9</td><td>qwen3-coder-flash</td><td>56.48</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>10</td><td>gemini-2.5-pro</td><td>55.66</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>11</td><td>gpt-5-high</td><td>55.56</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>12</td><td>llama-3.3-70b-instruct</td><td>54.72</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>13</td><td>qwen-2.5-coder-32b-instruct</td><td>53.77</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>14</td><td>qwen-2.5-72b-instruct</td><td>53.70</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>15</td><td>grok-code-fast-1</td><td>52.83</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>16</td><td>gemini-2.5-flash</td><td>52.78</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>17</td><td>gpt-4o</td><td>52.78</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>18</td><td>gpt-o3-mini-high</td><td>52.34</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>19</td><td>gpt-5</td><td>51.85</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>20</td><td>gpt-5-mini</td><td>51.85</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>21</td><td>llama-4-maverick</td><td>51.85</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>22</td><td>qwen3-coder</td><td>50.47</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>23</td><td>gpt-4o-mini</td><td>50.00</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>24</td><td>devstral-medium</td><td>50.00</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>25</td><td>qwen3-8b</td><td>49.07</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>26</td><td>devstral-small</td><td>48.15</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>27</td><td>gpt-oss-20b</td><td>48.15</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>28</td><td>gpt-5-nano</td><td>47.22</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>29</td><td>llama-4-scout</td><td>46.73</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>30</td><td>gemma-3-27b-it</td><td>46.50</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>31</td><td>qwen-qwen3-14b</td><td>46.30</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>32</td><td>qwen-qwen3-4b</td><td>45.79</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>33</td><td>mistralai-codestral-2508</td><td>44.44</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>34</td><td>qwen3-30b-a3b</td><td>43.52</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>35</td><td>mistral-small-3.2-24b-instruct</td><td>43.52</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>36</td><td>gpt-oss-120b</td><td>42.59</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>37</td><td>llama-3.1-405b-instruct</td><td>42.59</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>38</td><td>llama-3.3-8b-instruct</td><td>35.19</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>39</td><td>gemma-3n-e4b-it</td><td>32.08</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>40</td><td>glm-4.5</td><td>29.91</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>41</td><td>gemma-3-12b-it</td><td>24.30</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>42</td><td>deepseek-r1-0528</td><td>23.36</td><td><span class="tag is-success">Open</span></td></tr>
          </tbody>
        </table>
      </div>
      <p class="has-text-centered" style="margin-top: 1.5rem; font-size: 0.9rem; color: #666;">
        Full results available in <a href="heb-results.csv" style="color: #2563EB; font-weight: 600;">heb-results.csv</a>
      </p>
    </div>
  </div>
</section>
<!-- End leaderboard -->




<!-- What is EDIT-bench -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">What is EDIT-bench?</h2>
      <div class="content has-text-justified" style="font-size: 1.05rem;">
        <p>
          <strong>EDIT-bench</strong> (Evaluation of Developer Instructed Tasks) is a benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions. Unlike existing benchmarks that rely on synthetic or educational-style problems, EDIT-bench is constructed from actual developer workflows.
        </p>

        <h3 class="title is-5" style="margin-top: 1.5rem; color: #2563EB;">Data Collection</h3>
        <p>
          We developed an open-source VS Code extension that mimics existing instructed code editing tools like GitHub Copilot and Cursor. Nearly 500 developers used this extension in their daily coding workflows, allowing us to collect realistic user instructions, code contexts, highlighted code segments, and cursor positions.
        </p>

        <h3 class="title is-5" style="margin-top: 1.5rem; color: #2563EB;">Key Features</h3>
        <ul>
          <li><strong>Context-dependent problems:</strong> Models must understand user instructions, code context, highlighted code, and cursor position—just like in real AI coding assistants.</li>
          <li><strong>Diverse instructions:</strong> User instructions range from brief commands like "fix this" to detailed natural language descriptions or even raw error traces.</li>
          <li><strong>Real-world complexity:</strong> Problems span 74 unique Python libraries and various application domains (frontend/backend, ML, algorithms).</li>
          <li><strong>Multilingual:</strong> 5 natural languages (English, Spanish, Russian, Chinese, Portuguese) and 2 programming languages (Python, JavaScript).</li>
          <li><strong>Multiple task categories:</strong> Feature addition (43%), feature modification (27%), bug fixing (22%), and code optimization (8%).</li>
        </ul>

        <h3 class="title is-5" style="margin-top: 1.5rem; color: #2563EB;">Benchmark Statistics</h3>
        <p>
          EDIT-bench consists of <strong>545 problems</strong> with human-written test harnesses. We assembled a team of 5 experienced programmers to create test cases that adhere to user intent and are generalizable to different implementations. Each problem underwent a two-stage review process to ensure quality.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End What is EDIT-bench -->


<!-- How to Evaluate -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">How can I evaluate on EDIT-bench?</h2>
      <div class="content" style="font-size: 1.05rem;">
        <p class="has-text-justified">
          We provide a complete evaluation framework for running your models on EDIT-bench. Follow these steps to get started:
        </p>

        <div class="box" style="background-color: #F3F4F6; border-left: 4px solid #2563EB; margin-top: 1.5rem;">
          <h4 class="title is-5" style="margin-bottom: 1rem; color: #2563EB;">
            <span class="icon"><i class="fas fa-download"></i></span>
            Step 1: Clone the Repository
          </h4>
          <pre style="background-color: #1F2937; color: #F3F4F6; padding: 1rem; border-radius: 4px;"><code>git clone https://github.com/editbench/editbench.git
cd editbench</code></pre>
        </div>

        <div class="box" style="background-color: #F3F4F6; border-left: 4px solid #10B981; margin-top: 1.5rem;">
          <h4 class="title is-5" style="margin-bottom: 1rem; color: #10B981;">
            <span class="icon"><i class="fas fa-cog"></i></span>
            Step 2: Install Dependencies
          </h4>
          <pre style="background-color: #1F2937; color: #F3F4F6; padding: 1rem; border-radius: 4px;"><code>pip install -r requirements.txt</code></pre>
        </div>

        <div class="box" style="background-color: #F3F4F6; border-left: 4px solid #F59E0B; margin-top: 1.5rem;">
          <h4 class="title is-5" style="margin-bottom: 1rem; color: #F59E0B;">
            <span class="icon"><i class="fas fa-play"></i></span>
            Step 3: Run Evaluation
          </h4>
          <pre style="background-color: #1F2937; color: #F3F4F6; padding: 1rem; border-radius: 4px;"><code>python evaluate.py --model YOUR_MODEL_NAME</code></pre>
          <p style="margin-top: 1rem; font-size: 0.95rem;">
            The evaluation script will automatically:
          </p>
          <ul style="margin-left: 1.5rem; font-size: 0.95rem;">
            <li>Load the 545 EDIT-bench problems</li>
            <li>Generate code edits using your model</li>
            <li>Run test harnesses in isolated Docker containers</li>
            <li>Compute pass@1 metrics and save results</li>
          </ul>
        </div>

        <div class="box" style="background-color: #EEF2FF; border-left: 4px solid #8B5CF6; margin-top: 1.5rem;">
          <h4 class="title is-5" style="margin-bottom: 1rem; color: #8B5CF6;">
            <span class="icon"><i class="fas fa-book"></i></span>
            Documentation & Support
          </h4>
          <p>
            For detailed documentation, custom model integration, and troubleshooting, please see our <a href="https://github.com/editbench/editbench" style="color: #2563EB;"><strong>GitHub repository</strong></a>.
          </p>
          <p style="margin-top: 0.5rem;">
            To submit your results to the leaderboard, please open a pull request with your model's performance metrics.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End How to Evaluate -->






<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">Citation</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{editbench2026,
  title={EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits},
  author={Wayne Chi and Valerie Chen and Ryan Shar and Aditya Mittal and Jenny Liang and Wei-Lin Chiang and Anastasios Nikolas Angelopoulos and Ion Stoica and Graham Neubig and Ameet Talwalkar and Chris Donahue},
  journal={Under review as a conference paper at ICLR 2026},
  year={2026}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
