<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta name="description" content="A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers. EDIT stands for Evaluation of Developer Instructed Tasks.">
  <meta name="keywords" content="code editing, LLM benchmark, code generation, AI coding assistants, real-world evaluation, machine learning">
  <meta name="author" content="Wayne Chi, Valerie Chen, Ryan Shar, Aditya Mittal, Jenny Liang, Wei-Lin Chiang, Anastasios Nikolas Angelopoulos, Ion Stoica, Graham Neubig, Ameet Talwalkar, Chris Donahue">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Carnegie Mellon University">
  <meta property="og:title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta property="og:description" content="A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers. EDIT stands for Evaluation of Developer Instructed Tasks.">
  <meta property="og:url" content="https://editbench.github.io">
  <meta property="og:image" content="https://editbench.github.io/editbench-icon.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="EDIT-bench - Real-World Code Editing Benchmark">
  <meta property="article:published_time" content="2026-01-01T00:00:00.000Z">
  <meta property="article:author" content="Wayne Chi">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="code editing">
  <meta property="article:tag" content="LLM benchmark">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@CarnegieMellon">
  <meta name="twitter:creator" content="@CarnegieMellon">
  <meta name="twitter:title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta name="twitter:description" content="A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers. EDIT stands for Evaluation of Developer Instructed Tasks.">
  <meta name="twitter:image" content="https://editbench.github.io/editbench-icon.png">
  <meta name="twitter:image:alt" content="EDIT-bench - Real-World Code Editing Benchmark">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits">
  <meta name="citation_author" content="Chi, Wayne">
  <meta name="citation_author" content="Chen, Valerie">
  <meta name="citation_author" content="Shar, Ryan">
  <meta name="citation_author" content="Mittal, Aditya">
  <meta name="citation_author" content="Liang, Jenny">
  <meta name="citation_author" content="Chiang, Wei-Lin">
  <meta name="citation_author" content="Angelopoulos, Anastasios Nikolas">
  <meta name="citation_author" content="Stoica, Ion">
  <meta name="citation_author" content="Neubig, Graham">
  <meta name="citation_author" content="Talwalkar, Ameet">
  <meta name="citation_author" content="Donahue, Chris">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_pdf_url" content="https://editbench.github.io/edit-bench.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>EDIT-bench | Real-World Code Editing Benchmark</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/png" href="editbench-icon.png">
  <link rel="apple-touch-icon" href="editbench-icon.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits",
    "description": "A benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions collected in-the-wild from 500 developers.",
    "author": [
      {"@type": "Person", "name": "Wayne Chi", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Valerie Chen", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Ryan Shar", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Aditya Mittal", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Jenny Liang", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Wei-Lin Chiang", "affiliation": {"@type": "Organization", "name": "UC Berkeley"}},
      {"@type": "Person", "name": "Anastasios Nikolas Angelopoulos", "affiliation": {"@type": "Organization", "name": "UC Berkeley"}},
      {"@type": "Person", "name": "Ion Stoica", "affiliation": {"@type": "Organization", "name": "UC Berkeley"}},
      {"@type": "Person", "name": "Graham Neubig", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Ameet Talwalkar", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}},
      {"@type": "Person", "name": "Chris Donahue", "affiliation": {"@type": "Organization", "name": "Carnegie Mellon University"}}
    ],
    "datePublished": "2026-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "Carnegie Mellon University"
    },
    "url": "https://editbench.github.io",
    "image": "https://editbench.github.io/editbench-icon.png",
    "keywords": ["code editing", "LLM benchmark", "code generation", "AI coding assistants", "real-world evaluation", "machine learning"],
    "abstract": "Instructed code editing is becoming a widely used interaction mode in AI coding assistants. We introduce EDIT-bench, a benchmark for evaluating LLM code editing capabilities grounded in real-world usage with 545 problems collected from nearly 500 developers.",
    "isAccessibleForFree": true,
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://editbench.github.io"
    },
    "about": [
      {"@type": "Thing", "name": "Code Editing"},
      {"@type": "Thing", "name": "LLM Evaluation"}
    ]
  }
  </script>

  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Carnegie Mellon University",
    "url": "https://www.cmu.edu",
    "logo": "https://editbench.github.io/editbench-icon.png",
    "sameAs": [
      "https://twitter.com/CarnegieMellon",
      "https://github.com/editbench"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <div style="display: flex; align-items: center; justify-content: center; gap: 1rem; margin-bottom: 1rem;">
              <img src="editbench-icon.png" alt="EDIT-bench Logo" style="height: 80px; width: 80px;">
              <h1 class="title is-1 publication-title" style="margin-bottom: 0;">EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits</h1>
            </div>
            <div class="is-size-6 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Wayne Chi</a><sup>*1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Valerie Chen</a><sup>*1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ryan Shar</a><sup>*1</sup></span>
            </div>
            <div class="is-size-6 publication-authors">
              <span class="author-block">
                <a href="#" target="_blank">Aditya Mittal</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Jenny Liang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Wei-Lin Chiang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Anastasios Nikolas Angelopoulos</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ion Stoica</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Graham Neubig</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Ameet Talwalkar</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="#" target="_blank">Chris Donahue</a><sup>1</sup></span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="eql-cntrb"><small><sup>*</sup>Equal Contribution</small></span>
            </div>

            <div class="is-size-6 publication-authors" style="margin-top: 0.5rem;">
              <span class="author-block"><sup>1</sup>Carnegie Mellon University</span>
              &nbsp;&nbsp;
              <span class="author-block"><sup>2</sup>UC Berkeley</span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="edit-bench.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <span class="link-block">
                    <a href="https://github.com/editbench/editbench" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="results.csv" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-table"></i>
                  </span>
                  <span>Results</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- TLDR -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="title is-3 has-text-centered">TL;DR</h2>
      <div class="content has-text-justified" style="font-size: 1.1rem;">
        <p>
          <strong>EDIT-bench</strong> (Evaluation of Developer Instructed Tasks) is the first benchmark for evaluating LLM code editing capabilities built on <strong>real-world edit contexts and instructions</strong> collected in-the-wild. We gathered data from nearly 500 developers using a VS Code extension, creating 545 problems across 5 natural languages and 2 programming languages. EDIT-bench tests models on diverse, context-dependent problems that require understanding user instructions, code context, highlighted code, and cursor position—reflecting how developers actually use AI coding assistants.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End TLDR -->

<!-- Key Takeaways -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Key Takeaways</h2>
        <div class="content">
          <ul style="font-size: 1.05rem;">
            <li><strong>Real-world data:</strong> EDIT-bench is built from actual developer workflows, with user instructions and code contexts collected from 500 developers using our VS Code extension.</li>
            <li><strong>Challenging benchmark:</strong> Only 3 out of 40 models achieve over 60% pass@1, with claude-sonnet-4 leading at 66.67%.</li>
            <li><strong>Context matters:</strong> Model performance varies up to 11% depending on contextual information (highlighted code, cursor position), demonstrating the importance of realistic evaluation.</li>
            <li><strong>Diverse problems:</strong> 545 problems spanning 5 natural languages (English, Spanish, Russian, Chinese, Portuguese), 2 programming languages (Python, JavaScript), and 4 edit categories (feature addition, modification, bug fixing, optimization).</li>
            <li><strong>Model performance varies by task:</strong> Models excel at different problem categories—some are better at bug fixing (52.2% avg), while struggling with optimization (44.6% avg) and feature addition (39.6% avg).</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End key takeaways -->


<!-- Leaderboard -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">EDIT-bench Leaderboard</h2>
      <p class="has-text-centered" style="margin-bottom: 2rem;">
        Pass rates for 40 LLMs on EDIT-bench (545 problems). Higher is better.
      </p>
      <div class="table-container" style="max-height: 600px; overflow-y: auto; border: 1px solid #e5e7eb; border-radius: 8px;">
        <table class="table is-striped is-hoverable is-fullwidth" style="margin: 0;">
          <thead style="position: sticky; top: 0; z-index: 10;">
            <tr style="background-color: #2563EB; color: white;">
              <th style="color: white;">Rank</th>
              <th style="color: white;">Model</th>
              <th style="color: white;">Pass Rate (%)</th>
              <th style="color: white;">Type</th>
            </tr>
          </thead>
          <tbody>
            <tr><td>1</td><td>claude-sonnet-4</td><td><strong>66.67</strong></td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>2</td><td>gpt-o3-mini</td><td>63.89</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>3</td><td>claude-3.5-sonnet</td><td>62.04</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>4</td><td>claude-3-7-sonnet</td><td>59.48</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>5</td><td>deepseek-chat-v3.1</td><td>58.88</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>6</td><td>gpt-o4-mini-high</td><td>58.33</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>7</td><td>gpt-o4-mini</td><td>57.55</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>8</td><td>kimi-k2-0905</td><td>57.41</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>9</td><td>qwen3-coder-flash</td><td>56.48</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>10</td><td>gemini-2.5-pro</td><td>55.66</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>11</td><td>gpt-5-high</td><td>55.56</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>12</td><td>llama-3.3-70b-instruct</td><td>54.72</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>13</td><td>qwen-2.5-coder-32b-instruct</td><td>53.77</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>14</td><td>qwen-2.5-72b-instruct</td><td>53.70</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>15</td><td>grok-code-fast-1</td><td>52.83</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>16</td><td>gemini-2.5-flash</td><td>52.78</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>17</td><td>gpt-4o</td><td>52.78</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>18</td><td>gpt-o3-mini-high</td><td>52.34</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>19</td><td>gpt-5</td><td>51.85</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>20</td><td>gpt-5-mini</td><td>51.85</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>21</td><td>llama-4-maverick</td><td>51.85</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>22</td><td>qwen3-coder</td><td>50.47</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>23</td><td>gpt-4o-mini</td><td>50.00</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>24</td><td>devstral-medium</td><td>50.00</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>25</td><td>qwen3-8b</td><td>49.07</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>26</td><td>devstral-small</td><td>48.15</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>27</td><td>gpt-oss-20b</td><td>48.15</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>28</td><td>gpt-5-nano</td><td>47.22</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>29</td><td>llama-4-scout</td><td>46.73</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>30</td><td>gemma-3-27b-it</td><td>46.50</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>31</td><td>qwen-qwen3-14b</td><td>46.30</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>32</td><td>qwen-qwen3-4b</td><td>45.79</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>33</td><td>mistralai-codestral-2508</td><td>44.44</td><td><span class="tag is-danger">Closed</span></td></tr>
            <tr><td>34</td><td>qwen3-30b-a3b</td><td>43.52</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>35</td><td>mistral-small-3.2-24b-instruct</td><td>43.52</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>36</td><td>gpt-oss-120b</td><td>42.59</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>37</td><td>llama-3.1-405b-instruct</td><td>42.59</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>38</td><td>llama-3.3-8b-instruct</td><td>35.19</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>39</td><td>gemma-3n-e4b-it</td><td>32.08</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>40</td><td>glm-4.5</td><td>29.91</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>41</td><td>gemma-3-12b-it</td><td>24.30</td><td><span class="tag is-success">Open</span></td></tr>
            <tr><td>42</td><td>deepseek-r1-0528</td><td>23.36</td><td><span class="tag is-success">Open</span></td></tr>
          </tbody>
        </table>
      </div>
      <p class="has-text-centered" style="margin-top: 1.5rem; font-size: 0.9rem; color: #666;">
        Full results available in <a href="results.csv" style="color: #2563EB; font-weight: 600;">results.csv</a>
      </p>
    </div>
  </div>
</section>
<!-- End leaderboard -->




<!-- What is EDIT-bench -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">What is EDIT-bench?</h2>
      <div class="content has-text-justified" style="font-size: 1.05rem;">
        <p>
          <strong>EDIT-bench</strong> (Evaluation of Developer Instructed Tasks) is a benchmark for evaluating LLM code editing capabilities built on real-world edit contexts and instructions. Unlike existing benchmarks that rely on synthetic or educational-style problems, EDIT-bench is constructed from actual developer workflows.
        </p>

        <h3 class="title is-5" style="margin-top: 1.5rem; color: #2563EB;">Data Collection</h3>
        <p>
          We developed an open-source VS Code extension that mimics existing instructed code editing tools like GitHub Copilot and Cursor. Nearly 500 developers used this extension in their daily coding workflows, allowing us to collect realistic user instructions, code contexts, highlighted code segments, and cursor positions.
        </p>

        <h3 class="title is-5" style="margin-top: 1.5rem; color: #2563EB;">Key Features</h3>
        <ul>
          <li><strong>Context-dependent problems:</strong> Models must understand user instructions, code context, highlighted code, and cursor position—just like in real AI coding assistants.</li>
          <li><strong>Diverse instructions:</strong> User instructions range from brief commands like "fix this" to detailed natural language descriptions or even raw error traces.</li>
          <li><strong>Real-world complexity:</strong> Problems span 74 unique Python libraries and various application domains (frontend/backend, ML, algorithms).</li>
          <li><strong>Multilingual:</strong> 5 natural languages (English, Spanish, Russian, Chinese, Portuguese) and 2 programming languages (Python, JavaScript).</li>
          <li><strong>Multiple task categories:</strong> Feature addition (43%), feature modification (27%), bug fixing (22%), and code optimization (8%).</li>
        </ul>

        <h3 class="title is-5" style="margin-top: 1.5rem; color: #2563EB;">Benchmark Statistics</h3>
        <p>
          EDIT-bench consists of <strong>545 problems</strong> with human-written test harnesses. We assembled a team of 5 experienced programmers to create test cases that adhere to user intent and are generalizable to different implementations. Each problem underwent a two-stage review process to ensure quality.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End What is EDIT-bench -->


<!-- How to Evaluate -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">How can I evaluate on EDIT-bench?</h2>
      <div class="content" style="font-size: 1.05rem;">
        <p class="has-text-justified">
          To evaluate your model on EDIT-bench, please visit our GitHub repository and follow the detailed instructions in the README:
        </p>

        <div class="box" style="background-color: #F3F4F6; border-left: 4px solid #2563EB; margin-top: 1.5rem; text-align: center;">
          <h4 class="title is-4" style="margin-bottom: 1.5rem; color: #2563EB;">
            <span class="icon"><i class="fab fa-github"></i></span>
            Get Started on GitHub
          </h4>
          <a href="https://github.com/editbench/editbench" target="_blank" class="button is-large" style="background-color: #2563EB; color: white; font-weight: 600; padding: 1.5rem 3rem; border-radius: 8px;">
            <span class="icon is-medium">
              <i class="fab fa-github"></i>
            </span>
            <span>View Repository & README</span>
          </a>
          <p style="margin-top: 1.5rem; font-size: 0.95rem; color: #666;">
            The README includes complete setup instructions, evaluation scripts, and submission guidelines.
          </p>
        </div>

        <div class="content" style="margin-top: 2rem;">
          <h4 class="title is-5" style="color: #1F2937;">What you'll find in the repository:</h4>
          <ul style="font-size: 1rem;">
            <li><strong>Complete benchmark dataset:</strong> All 545 EDIT-bench problems with test harnesses</li>
            <li><strong>Evaluation scripts:</strong> Ready-to-use code for running your models</li>
            <li><strong>Docker setup:</strong> Isolated testing environment configuration</li>
            <li><strong>Submission guidelines:</strong> Instructions for adding your results to the leaderboard</li>
            <li><strong>Documentation:</strong> Detailed guides for custom model integration</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End How to Evaluate -->






<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">Citation</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{editbench2026,
  title={EDIT-bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits},
  author={Wayne Chi and Valerie Chen and Ryan Shar and Aditya Mittal and Jenny Liang and Wei-Lin Chiang and Anastasios Nikolas Angelopoulos and Ion Stoica and Graham Neubig and Ameet Talwalkar and Chris Donahue},
  journal={Under review as a conference paper at ICLR 2026},
  year={2026}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
